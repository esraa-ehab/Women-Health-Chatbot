{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16d646a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "\n",
    "def load_pdf_chunks(file_path, chunk_size=500):\n",
    "    reader = PdfReader(file_path)\n",
    "    full_text = \"\"\n",
    "    for page in reader.pages:\n",
    "        full_text += page.extract_text() or \"\"\n",
    "    chunks = [full_text[i:i + chunk_size] for i in range(0, len(full_text), chunk_size)]\n",
    "    return chunks\n",
    "\n",
    "pdf_chunks = load_pdf_chunks(\"womens_health_book.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64fb822b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "def get_embedding(text):\n",
    "    model = \"models/text-embedding-004\"\n",
    "    response = genai.embed_content(\n",
    "        model=model,\n",
    "        content=text,\n",
    "        task_type=\"retrieval_document\"\n",
    "    )\n",
    "    return response['embedding']\n",
    "\n",
    "embedding_data = []\n",
    "for chunk in pdf_chunks:\n",
    "    vector = get_embedding(chunk)\n",
    "    embedding_data.append({\"text\": chunk, \"embedding\": vector})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4824fcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "client = chromadb.Client(Settings(anonymized_telemetry=False))\n",
    "collection = client.create_collection(name=\"womens_health\")\n",
    "\n",
    "for idx, item in enumerate(embedding_data):\n",
    "    collection.add(\n",
    "        documents=[item[\"text\"]],\n",
    "        embeddings=[item[\"embedding\"]],\n",
    "        ids=[str(idx)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "789b6166",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def handle_small_talk(prompt):\n",
    "    small_talk_responses = {\n",
    "        \"hi\": \"Hello! How can I help you today?\",\n",
    "        \"hello\": \"Hi there! How can I assist you?\",\n",
    "        \"how are you\": \"I'm just a chatbot, but I'm here and ready to help!\",\n",
    "        \"good morning\": \"Good morning! How can I assist you today?\",\n",
    "        \"good evening\": \"Good evening! Feel free to ask me anything.\",\n",
    "        \"thanks\": \"You're welcome!\",\n",
    "        \"thank you\": \"You're welcome!\",\n",
    "        \"bye\": \"Goodbye! Take care.\",\n",
    "    }\n",
    "\n",
    "    prompt_clean = prompt.lower().strip()\n",
    "    return small_talk_responses.get(prompt_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5b612d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question(question, top_k=3):\n",
    "    small_talk = handle_small_talk(question)\n",
    "    if small_talk:\n",
    "        return small_talk\n",
    "\n",
    "    results = collection.query(\n",
    "        query_embeddings=[get_embedding(question)],\n",
    "        n_results=top_k\n",
    "    )\n",
    "    context = \"\\n\\n\".join(results[\"documents\"][0])\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are a helpful and friendly women's health assistant.\n",
    "    Use the following information to answer health-related questions.\n",
    "    If the user's message is a greeting or casual, respond appropriately.\n",
    "\n",
    "    Context:\n",
    "    {context}\n",
    "\n",
    "    User: {question}\n",
    "    \"\"\"\n",
    "    model = genai.GenerativeModel(\"models/gemini-1.5-pro-latest\")\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cb9164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Women with PCOS may experience a variety of symptoms, including irregular or prolonged menstrual periods, excess androgen levels (which can lead to acne, hirsutism, and male-pattern baldness), and the development of numerous cysts on the ovaries.  It's important to note that the intensity of symptoms can range from mild to quite severe, and not all women will experience every symptom.  If you are concerned you might have PCOS, it's crucial to consult a healthcare professional for proper diagnosis and management.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question = \"What are the symptoms of PCOS?\"\n",
    "response = ask_question(question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca1d221c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/embedding-gecko-001 ['embedText', 'countTextTokens']\n",
      "models/gemini-1.0-pro-vision-latest ['generateContent', 'countTokens']\n",
      "models/gemini-pro-vision ['generateContent', 'countTokens']\n",
      "models/gemini-1.5-pro-latest ['generateContent', 'countTokens']\n",
      "models/gemini-1.5-pro-001 ['generateContent', 'countTokens', 'createCachedContent']\n",
      "models/gemini-1.5-pro-002 ['generateContent', 'countTokens', 'createCachedContent']\n",
      "models/gemini-1.5-pro ['generateContent', 'countTokens']\n",
      "models/gemini-1.5-flash-latest ['generateContent', 'countTokens']\n",
      "models/gemini-1.5-flash-001 ['generateContent', 'countTokens', 'createCachedContent']\n",
      "models/gemini-1.5-flash-001-tuning ['generateContent', 'countTokens', 'createTunedModel']\n",
      "models/gemini-1.5-flash ['generateContent', 'countTokens']\n",
      "models/gemini-1.5-flash-002 ['generateContent', 'countTokens', 'createCachedContent']\n",
      "models/gemini-1.5-flash-8b ['createCachedContent', 'generateContent', 'countTokens']\n",
      "models/gemini-1.5-flash-8b-001 ['createCachedContent', 'generateContent', 'countTokens']\n",
      "models/gemini-1.5-flash-8b-latest ['createCachedContent', 'generateContent', 'countTokens']\n",
      "models/gemini-1.5-flash-8b-exp-0827 ['generateContent', 'countTokens']\n",
      "models/gemini-1.5-flash-8b-exp-0924 ['generateContent', 'countTokens']\n",
      "models/gemini-2.5-pro-exp-03-25 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-pro-preview-03-25 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-flash-preview-04-17 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-flash-preview-04-17-thinking ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-pro-preview-05-06 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-exp ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
      "models/gemini-2.0-flash ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-001 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-lite-001 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-lite ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-lite-preview-02-05 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-lite-preview ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-pro-exp ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-pro-exp-02-05 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-exp-1206 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-thinking-exp-01-21 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-thinking-exp ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-thinking-exp-1219 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/learnlm-2.0-flash-experimental ['generateContent', 'countTokens']\n",
      "models/gemma-3-1b-it ['generateContent', 'countTokens']\n",
      "models/gemma-3-4b-it ['generateContent', 'countTokens']\n",
      "models/gemma-3-12b-it ['generateContent', 'countTokens']\n",
      "models/gemma-3-27b-it ['generateContent', 'countTokens']\n",
      "models/embedding-001 ['embedContent']\n",
      "models/text-embedding-004 ['embedContent']\n",
      "models/gemini-embedding-exp-03-07 ['embedContent', 'countTextTokens']\n",
      "models/gemini-embedding-exp ['embedContent', 'countTextTokens']\n",
      "models/aqa ['generateAnswer']\n",
      "models/imagen-3.0-generate-002 ['predict']\n",
      "models/gemini-2.0-flash-live-001 ['bidiGenerateContent', 'countTokens']\n"
     ]
    }
   ],
   "source": [
    "models = genai.list_models()\n",
    "for m in models:\n",
    "    print(m.name, m.supported_generation_methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9a8530",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
